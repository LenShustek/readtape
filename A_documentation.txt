READTAPE: A program to recover data from old computer magnetic tapes 

OVERVIEW 

This software, continually in development, analyzes the analog signal from
a multi-track digital magnetic tape to reconstruct the original digital 
data. The motivation for starting with the analog data is to be able to 
recover data that has degraded to the point where conventional tape 
drives won't read it, or to recover data when a drive for obsolete media
is no longer available.

This is open-source code at https://github.com/LenShustek/readtape.
- See VCF_Aug2020_01.pdf for a slide show about the system.
- See https://www.youtube.com/watch?v=7YoolSAHR5w&t=4200s for a bad-
  quality video of me giving a talk using that slideshow.
- For a detailed change log, see the beginning of src\readtape.c.

The input to the READTAPE program is a sequence of periodic samples of 
the analog voltage from all channels of the read head as the tape is 
moving. The output is the reconstructed original data that was recorded
on the tape, and a log that indicates how successful it was.

We have used Qualstar 1052 tape drives to generate some of the data,
with either a 9-track or 7-track head installed. The drive manual is here: 
http://bitsavers.trailing-edge.com/pdf/qualstar/500150B_1052serviceMan.pdf.  
The analog samples are taken from the output of the second-stage 
amplifiers in the front end, which is pin 1 of Ux02A shown in the 
schematic on page 91. The drive is put in diagnostic read mode, which 
causes the tape to move past the head without needing to send any 
commands over the computer interface. Other tape drives (Qualstar 3418S,
Kennedy 9600) have been used for 9-track 6250 BPI tapes encoded with GCR.

The analog to digital conversion is from a Saleae 16-channel logic 
analyzer (https://www.saleae.com/), which does 12-bit digitization (4096 
possible values) of single-ended signals from -10V to +10V. Having 
bipolar inputs is important, because the output of the second operational 
amplifier of the Qualstar drive is typically +-2V to +-6V. For degraded 
areas of the tapes it goes lower, but automatic gain control in the 
software allows it to decode signals that go as low as +-0.1V. 

The canonical internal order for the track data is: MSB...LSB, and then 
PARITY, connected to logical analyzer probes starting with number 0. 
If another order is used, the program can be told about that. 

I've used different sample rates depending on the density and drive 
speed, but the goal is to get about 20 samples per cycle. For 800 BPI 
NRZI at 50 IPS, the Saleae 781 Khz rate works well. For 1600 BPI PE 
tapes, their 1.56 Mhz rate is a good choice. The analyzer supports rates 
as high as 50 Mhz. 

The logic analyzer streams the data to a computer over a type 3.0 USB 
port. The data is stored in the computer's virtual memory, so the time 
and space limits are set by the memory/disk speed and size. Recording 
for many minutes to create files that take dozens of gigabytes hasn't 
been a problem. The data is in Saleae's proprietary format, but then
some or all of the file can exported to a text file.

The only form in which data can be exported from the Saleae analyzer 
software is a CSV (comma-separated-value) text file with a series of 
floating point numbers. The first number on each line is a timestamp in 
seconds, and the next N values on the lines are the voltages from the N 
tracks. The readtape program can read that file. 

But the CSV files can be huge -- many tens of gigabytes for a few 
minutes of recording -- so for archival purposes we've defined a binary 
compressed "TBIN" format that uses 16-bit integers instead of floating 
point, and I wrote a utility program that can convert between CSV and 
TBIN. The compression factor is about 10:1, and the processing is about 
2x faster when the program reads that file format. There is some loss of 
precision in the compressed format, but not enough to affect the decoding. 


USING THE PROGRAM 

This is a command-line (non-GUI) program written in standard C. I use it
on a Windows PC, but it should work in other environments too. It contains
code to detect whether the processor is little-endian or bit-endian, and
it reverses numbers in external files when necessary. I compile and link
using Microsoft Visual Studio Community 2017.

use: readtape <options> <basefilename>
  the input file is <basefilename>.csv or <basefilename>.tbin
  the output files will be <basefilename>.xxx by default
  the optional parameter file is <basefilename>.parms,
   or NRZI/PE/GCR/Whirlwind.parms, in the base or current directory

options:
  -ntrks=n       set the number of tracks
  -order=        set input data order for tracks 0..ntrks-2,P, where 0=MSB
                 default: 01234567P for 9 trk, 012345P for 7 trk
                 (for Whirlwind: a combination of C L M c l m and x's)
  -pe            PE (phase encoding)
  -nrzi          NRZI (non return to zero inverted)
  -gcr           GCR (group coded recording)
  -whirlwind     Whirlwind I 6-track 2-bit-per-character
  -ips=n         speed in inches/sec (default: 50, except 25 for GCR)
  -bpi=n         density in bits/inch (default: autodetect)
  -zeros         base decoding on zero crossings instead of peaks
  -differentiate do simple delta differentiation of the input data
  -even          expect even parity instead of odd (for 7-track NRZI BCD tapes)
  -invert        invert the data so positive peaks are negative and vice versa
  -fluxdir=d     flux direction is 'pos', 'neg', or 'auto' for each block
  -reverse       reverse bits in a word and words in a block (Whirlwind only)
  -skip=n        skip the first n samples
  -blklimit=n    stop after n blocks
  -subsample=n   use only every nth data sample
  -tap           create one SIMH .tap file from all the data
  -deskew        do NRZI track deskewing based on the beginning data
  -skew=n,n      use this skew, in #samples for each track, rather than deducing it
  -correct       do error correction, where feasible
  -addparity     include the parity bit as the highest bit in the data (for ntrks<9)
  -tbin          only look for a .tbin input file, not .csv first
  -nolog         don't create a log file
  -nolabels      don't try to decode IBM standard tape labels
  -textfile      create an interpreted .<options>.txt file from the data
                   numeric options: -hex -octal (bytes) -octal2 (16-bit words)
                   character options: -ASCII -EBCDIC -BCD -sixbit -B5500 -SDS -SDSM -flexo
                   characters per line: -linesize=nn
                   space every n bytes of data: -dataspace=n
                   make LF or CR start a new line: -linefeed
  -outf=bbb      use bbb as the <basefilename> for output files
  -outp=ppp      otherwise use ppp as an optional prepended path for output files
  -sumt=sss      append a text summary of results to text file sss
  -sumc=ccc      append a CSV summary of results to text file ccc
  -m             try multiple ways to decode a block
  -nm            don't try multiple ways to decode a block
  -v[n]          verbose mode [level n, default is 1]
  -q             quiet mode (only say "ok" or "bad")
  -f             take a file list from <basefilename>.txt
  
For Whirlwind, don't specify the number of tracks. Instead, the -order parameter 
specifies the assignment of input data (the heads) to tracks, as follows:
  - The length of the -order parameter is the number of data columns
    we expect to find in the input file.
  - Each character, in order of the data in the file, is one of these:
       x   meaning don't use this data
       C   for the primary clock track
       M   for the primary most significant bit track
       L   for the primary least significant bit track
       c   for the alternate clock track
       m   for the alternate most significant bit track
       l   for the alternate least significant bit track
   - Not all alternates need be present, but all primaries do.
   - The number of tracks we wind up processing can therefore range
     from 3 to 6.

By default, each set of records between tapemarks is stored as separate 
file. If it detects IBM standard labels, it uses those to name the files 
and doesn't write the labels themselves. In -tap mode, it instead creates
one tape image file in SIMH .tap format; see
http://simh.trailing-edge.com/docs/simh_magtape.pdf. 

Decoding is controlled by a set of parameters that adjust the 
algorithms. No one set of parameters will necessarily work for all tapes 
or even all blocks of one tape. You can specify multiple sets of 
parameters, and the program will try as many as necessary to get a 
perfect decoding of a block, or will try them all and pick the one that 
generates the minimum number of errors. There are additional parameters
that are #define constants in the program which can only be changed by
recompiling.

The sets of parameters that are used for the decoding algorithms can 
be read from a file that is specific to the tape data being decoded, 
<basefilename>.parms, or from a generic file for that encoding type 
(NRZI.parms, PE.parms, etc.). If no parameter file is provided, the 
program uses built-in defaults. 

The algorithms are still a work in progress, so the parameter sets 
will continue to evolve. The current set of parameters are these,
some of which apply to only some of the encoding schemes. To make
sense of some of these you have to understand the decoding algorithms
described later.

   int active;             // 1 means this is an active parameter set
   int clk_window;         // how many bit times to average for clock rate; 0 means maybe use exponential averaging
   float clk_alpha;        // weighting for current data in the clock rate exponential weighted average; 0 means use constant
   int agc_window;         // how many peaks to look back for the min peak to set AGC; 0 means maybe use exponential averaging
   float agc_alpha;        // weighting for current data in the AGC exponential weight average; 0 means no AGC
   float min_peak;         // peak detection: the minimum height of a peak in volts, above or below 0 volts (not relative!)
   float clk_factor;       // PE: how much of a half-bit period to wait for a clock transition
   float pulse_adj;        // PE: how much of the previous pulse's deviation to adjust this pulse by, 0 to 1
   //                         NRZI: how much of the actual transition avg position to use to adjust the next expected
   float pkww_bitfrac;     // what fraction of the bit spacing the window width is
   float pkww_rise;        // the required rise in volts in the window that represents a peak (will be adjusted by AGC and peak height)
   float midbit;           // NRZI: what fraction of a bit time is the midbit point for determining zeroes
   float z1pt;             // GCR: fraction of a bit time that means one zero bit
   float z2pt;             // GCR: fraction of a bit time that means two zero bits
   char id[4];             // "PRM", to make sure the structure initialization isn't screwed up

The format of a parameter file is as follows:

//  comments
readtape <additional command line options>
parms active, clk_window,  clk_alpha, agc_window, agc_alpha, min_peak, clk_factor, pulse_adj, pkww_bitfrac, pkww_rise, id
 {1,   0,     0.2,      5,    0.0,    0.0,   1.50,    0.4,   0.7,  0.10, "PRM" }
 {1,   3,     0.0,      5,    0.0,    0.0,   1.40,    0.0,   0.7,  0.10, "PRM" }
...

The leading 1 indicates an active parameter set, and the trailing "PRM" 
is for error checking. The numbers in between are the parameters, in the 
order given by the "parms" line of the file. 

If there is a now-obsolete parameter name in the file that the program 
no longer knows about, it is ignored with a warning. If a parameter name 
that the program expects is missing, the value from the first built-in 
parameter set is used. This scheme allows us to add and remove parameters 
in the program without invalidating existing .parm files. 

Parameter sets are used in sequence for each block on the tape to find 
the best decoding. In verbose mode, the program reports on how many 
times each parameter set was successfully used to decode any block. 

Before diving into the code to fiddle with the algorithms, try creating
new parameter sets and see if that helps get a clean decode. Most of 
the time it can.  Often, though, you will need to use some of the debugging
features to get a hint about what parameters need to be tweaked. This
is not a turn-key operation, especially for marginal tapes! And setting
the parameters can be more art than science.

There are other constant parameters for the algorithms that are defined 
in the decoder.h header file. As we discover any of them that need to 
have multiple values to decode all blocks we've encountered, they get 
moved into the parameter sets. 


SUMMARY OF TAPE FORMATS

I keep forgetting this stuff, so for the record, here's a terse 
description of the various tape formats we process. 

*** 9-track 1600 BPI PE (phase encoded)
- track order is P37521064, where 0=msb and P=parity
- negative flux transition is usually a 0-bit, positive a 1-bit 
  (But it might be reversed! The first transition is always a 0-bit)
- optional flux transition as needed at the midpoint between bits
- block preamble is about 40 0-bits on all tracks, then a 1-bit on all tracks
- block postamble is a 1-bit on all tracks, then about 40 0-bits, then silence
- odd parity on each byte
- no end-of-block check bytes
- tape mark: about 40 0-bits on tracks 0,2,5,6,7,P; silence on 1,3,4
- at load point of tape: 1600 flux reversals on track P only

*** 9-track 800 BPI NRZI (non-return-to-zero inverted)
- track order is P37521064, where 0=msb and P=parity
- either flux transition is a 1-bit, no transition is a 0-bit
- no block preamble or postamble
- odd parity on each byte
- CRC character is 4 character times after the end of the block
- LRC character is 4 character times after that, and includes the CRC
- tape mark: 1-bits on tracks 3,6,7, then 8 bit times, then the same

*** 7-track 200/556/800 BPI NRZI
- track order is P012345, where 0=msb and P=parity
- either flux transition is a 1-bit, no transition is a 0-bit
- no block preamble or postamble
- odd parity on each byte for binary data, even parity for BCD text
  (For IBM 729, spaces in memory (0) are converted to 0x10 on tape, 
  to avoid having BCD text create no transitions on any tracks.)
- LRC character is 4 character times after the end of the block, and
  it could have bad parity; no CRC character
- tape mark: 1-bits on tracks 8,4,2,1, then 4 bit times, then the same

*** 6-track 100 BPI NRZI Whirlwind tapes
- track order is (sometimes) CLMCLM, where C is the clock track, and L M 
  are LSB/MSB data tracks. Each track appears twice, for redundancy, but
  the order varies depending on which Whirlwind drive wrote the tape.
- 100 bits/inch 
- in data blocks, 8 consecutive 2-bit characters are assembled into one
  a 16-bit word, most significant bits first
- a flux transition is a 1-bit, and no signal is a zero bit
- flux transitions can be low-then-high, or high-then-low, depending on the
  drive it was recorded on. Tapes were liberally reused, so some tapes have
  a mixture of both kinds.
- during a data block there is a flux transition on both clock tracks at 
  every bit position 
- a tape mark is a 1-bit on the LSB data tracks, and nothing on the clock tracks
- a tape mark may appear in isolation, or *immediately* before or after a 
  data block, ie within the normal bit time
  
*** 9-track 6250 BPI GCR
- track order is 573P21064, where 0=msb and P=parity
- bit encoding is NRZI: transition for 1-bit, none for 0-bit
- block preamble is 80 bytes: 10101, 01111, 14x11111 in all tracks
- then 00111 ("Mark 1") in all tracks, then data starts
- each 7 data bytes gets an 8th ECC character appended
- those 8 bytes ("data group") are encoded into 10 bytes ("storage group")
  using a 4-bit to 5-bit translate table twice for each track. The coding
  guarantees no more than two consecutive zero bits in any track.
- the P track is odd parity in 4-bit data groups, before conversion to 5-bits.
- actual parity on the tape can be even or odd!
- after every 158 storage groups a 20-byte resync burst is inserted, which is
  11100 ("Mark 2") 11111 11111 ("End Marks") 00111 ("Mark 1") on all tracks
- after the last full multiple of 7 data bytes: 11111 ("End Mark")
- then one more 8-byte "residual" data group, containing the remaining 0 to 6
  data bits (zero-padded) an auxiliary CRC, and the usual ECC
- then an 8-byte CRC group (which also encodes how many pad bits there were)
- then 11100 ("Mark 2")
- block postamble is 80 bytes: 14x11111, 11110, 1010L in all tracks,
  where L "restores the magnetic remanence to the erase state", which means
  a 0 or 1 such that the last peak was positive.
- the actual bit density would be 6250*10/7 = 8929 BPI just for group recoding,
  but to account for the sync bursts it is 8929 *(1+20/1580) = 9042 BPI
  (That's 2.21 usec/bit at 50 IPS, or 4.42 usec/bit at 25 IPS)
- tape mark: 250 to 400 flux changes at 9042 on tracks 2,5,8,1,4,7; silence on 3,6,9
- at the BOT marker there is an ID burst (1.7" of only track 6 transitions),
  then a Auto Read Amp burst (2" of 1s on all tracks, then 2" of 1s on 2,3,5,6,8,9)
- Whew!


THE ALGORITHMS

This system is still under development, so the algorithms will probably 
have changed by the time you read these descriptions. 

Peak Detection

As the tape moves past the head, a flux transition on any track creates 
a voltage peak, either positive or negative, in accordance with 
Faraday's Law, V = dB/dT. The amplitude of the voltage depends on many 
things: tape speed, bit density, head design, track alignment, the 
exact sequence of flux transitions, how well the tape was recorded, and
the condition of the tape.

For the Qualstar drives we record the analog signal after a 
differential amplifier, a low-pass filter, and a differential to 
single-ended amplifier in the drive electronics. The signal is amazingly 
clean, with little noise or jitter that isn't attributable to the data 
on the tape. 

The first version of software peak detection used a hill-climbing 
algorithm to detect a local minimum or maximum. We kept track of whether 
we were going uphill or downhill, and recorded a peak when the direction 
changed by a non-trivial amount. The actual time of the peak was 
calculated by interpolating the times of samples that were close the the 
peak. 

The problem, especially when combined with the AGC algorithm described 
later, was the generation of false positives when the signal is small or 
when there are small variations. Tweaking the parameters to avoid that 
would suppress valid peaks. It would work when the parameters were 
carefully adjusted for a particular tape, but it was not robust. 

The second version of peak detection, which seems to work better, uses a 
moving window shape detector. We keep track of the last N samples for 
each track, of course using a circular buffer with head and tail 
pointers so the data doesn't have to be moved. As each new data point 
enters the window, we look to see if the maximum (minimum) sample is 
much higher (lower) than the oldest and newest values, and record a peak 
if so. We then become blind to peaks until that peak exits the window. 

This second algorithm works well as long as the peaks are relatively 
sharp. If the peaks have flat tops or bottoms, perhaps because of 
clipping in the electronics, the window size needs to be large, at which 
point multiple narrow sharp peaks elsewhere in the data won't be 
detected because more than one appears in the window. In that case, 
consider (see below) differentiating the signal using the -differentiate 
option, and check for zero-crossings instead of peaks using the -zeros 
option. 

The number of samples in the window is set dynamically based on the 
sampling rate, the expected bit rate, and the pkww_bitfrac parameter. 
The amount by which a peak has to exceed the oldest and newest values is 
also parametrized as pkww_rise, and is modified by the current AGC. The 
time of the peak is interpolated based on the previous and next sample 
values, so that two or three values close to the peak are averaged. 

Compensation for "pulse shifting", which depends on the sequence and 
proximity of flux transitions, is done by computing the difference 
between the possible expected position of the pulse (which depends on 
the kind of encoding used) and the observed position. The pulse_adj 
parameter controls what fraction of that distance should be used to 
adjust the time of the peak before using it in the decoding algorithm. 

Zero-crossing detection

Depending on the tape drive, the point in the low-level electronic 
processing at which the analog-to-digital conversion is made, and whether
the option to differentiate the signal has been chosen, zero-crossing 
detection might be needed instead of peak detection to identify the bit data.
The -zeros parameter enables that. 

In the code, the terminology used is that either "peaks" or "crossings"
cause up-down "transitions", whose timing is analyzed to extract bits.

The zero-crossing detection algorithms are relatively simple and assume a 
minimum amount of jitter. There are two algorithms:

- For data that has not been differentiated, it makes sure that the peak 
between crossings is bigger than the ZEROCROSS_PEAK parameter before 
recording the crossing, and that the peak is attained within 
ZEROCROSS_SLOPE bit times after the crossing. 

- For data that has been differentiated (see below), any zero-crossing
after an excursion of at least ZEROCROSS_PEAK (0.2V) is treated as a 
valid crossing. If there are actual zeros between the non-zero samples,
the time of the crossing is taken to be the midpoint of them all. If there
are no zeros, the time of the crossing is halfway between the two samples
that straddle zero.

Differentiation

Depending on the signal being digitized in the tape drive, it's sometimes
helpful to take a rough first derivative of the signal and look for zero-
crossings instead of peaks. To do that, specify the -differentiate and 
-zeros parameters. It's especially helpful when the signal is being clipped
and peaks become flattened.

The differentiation is done early, when the data is being read from the 
file. The deltas are scaled by DIFFERENTIATE_SCALE (0.4) times the 
number of samples/bit, to create a reasonable range. 

Any deltas of consecutive samples less than DIFFERENTIATE_THRESHOLD 
(typically 0.05 volts) are considered to be zero, in order to avoid 
false transitions. That tends to create a string of zeros in the 
vicinity of the peak, and the -zeros parameter in that case takes the 
location of the former peak to be the center of all the zeros. 

AGC: Automatic Gain Control

To compensate for differences in signal amplitude between tapes, between 
blocks, and between bits, we keep track of the average or expected peak 
heights for each track separately. The calculation produces an AGC value 
between 0.1 (for big signals) and 20 (for small signals). We change it by 
one of two algorithms: 

- exponential averaging: the new value is alpha * current + (1-alpha) * 
old average. This provides a kind of low-pass filter so that the gain
changes slowly. 

- recent minimum: the value is based on the minimum peak of the 
last N peaks we've seen. (Again, implemented with a circular buffer with 
head and tail pointers so stored data doesn't have to be moved.) This 
works better for some tapes where there are isolated very small peaks. 

The AGC value is used for the following two calculations: 

- choosing how high or low a voltage must be to be considered a peak 

- adjusting how close adjacent samples near the peak need to be for 
their times to be averaged 

High values of AGC let us detect peaks that are as small as 0.1V during 
dropouts on a particular track, yet still be able to ignore noise at 
other times when the signal is strong. 

Clock Recovery

...TBD..  window and exponential averaging here too..

PE Decoding Techniques

PE (phase encoding) has a negative flux transition for a 0-bit and a 
positive flux transition for a 1-bit. At the midpoint between bits, 
there is an optional flux transition if needed to prepare for the 
correct next bit flux transition. This is sometimes described as 
"Manchester" encoding. 

...TBD... setting the decision point...

NRZI Decoding Techniques

NRZI (non return to zero inverted) encoding has a flux transition of 
either direction for a 1-bit, and no transition for a 0-bit. Recovering 
the clock depends on there being frequent 1-bits in at least one track. 
My algorithm for NRZI decoding tolerates some track-to-track skew by 
working as follows: 

- Average the time that multiple tracks have "nearby" transitions, and 
use that as the assumed bit time. 

- The time between successive bit times establishes the data frequency, 
whose change over time is smoothed either by averaging over a fixed 
number of bits or by exponential weighting. 

- The time of any particular track's transition is compared to the 
expected bit time, and a settable fraction (50% seems to work well) of 
the deviation is used to adjust the transition time. (That tweak was 
added to compensate for data-dependent peak-shifting, but it helps
for modest amounts of track skew too.) 

- The decision about whether a track lacked a transition at a bit time 
used to be made about halfway (0.65 seemed to work well) between bit 
times. The time for this computation was controlled by the "midbit" 
parameter as a fraction of a bit after the bit transition time.

The problem was that shallow pulses weren't detected in time, resulting 
in some one bits that should have been counted being discovered after 
the decision point. So we moved the decision point to the next bit 
transition time, and we look back at a bit-size window surrounding the 
previous bit transition time. To do that, we keep track of the time of 
the last peak and the peak before that for each track, and see if either 
falls inside the window. If so, we count it as a one bit.

Note that this requires all track data to be processed together, not
independently like for PE and GCR. It is important, therefore, for head
skew (see later section) to be measured and adequately adjusted for.

GCR Decoding Techniques

Since GCR is fundamentally NRZI encoding with additional constraints 
and redundancy, my first attempt was to use the working NRZI decoder,
and then post-process the redundancy at the end of the block.

The problem was that at the 9042 BPI bit density, head skew calibration 
needs to be extremely aggressive and accurate. The skew can, according 
to the ANSI X3.54 spec, be as much 664 microinches, or 6 bit times. (Why 
in the March 1985 HP Journal article on the HP 7978A do they talk about 
"the maximum allowable skew of 25 bits"?) In any event, I have certainly 
seen 3 bit times of skew. 

What's worse, the skew seems to be totally different from block to block!
I don't know why that is, but it would require recalibrating the skew
at the start of each block.

Also, the pulse shifts because of 0-1 and 1-0 bit sequencing are a pretty 
big fraction of the bit time, making it very difficult to find a single 
right mid-bit position for all tracks to record "missing" 0-bits. I got 
this scheme to work for many blocks by carefully tuning the decoding 
parameters for particular blocks, but it wasn't robust. 

Since GCR limits the number of consecutive 0-bits to two, it is instead
possible, unlike for standard NRZI, for the clock to be separately recovered
for each track. So we switched a scheme more like PE, where each track's
data is separately reconstructed. Head skew is then irrelevant. After all
the tracks have gone silent at the end of a block, the data bits are aligned,
and the post-processing to remove the redundancy happens.

Since consecutive 0-bits are limited to two, we don't use the 
hard-to-set "midbit" time to determine if a zero occurred, as we do for 
for NRZI. Instead, we wait for the next 1-bit pulse, and determine if it 
came one bit time (no zeros), two bit times (one zero), or three bit 
times (two zeros) after the last peak. 

As the data is processed, we accumulate the raw bits. At the end of the 
block, we post-process the data to recognize the special groups, do the 
5-bit to 4-bit decompression, and check the parity and ECC. 

In summary, here is the process followed for GCR decoding:
- record analog data from the 9 tape heads sampled at 3.1 Mhz and 25 IPS
- do 12-bit A-to-D conversion of each sample to a digital voltage level
- detect peaks and recover the clock on each track independently
- do the NRZI decoding to recover the bit stream for each track
- reorder the tracks to be (msb)...(lsb),parity
- align the tracks (which compensates for skew) into a sequence of 9-bit-wide "bytes"
- divide the sequences into 5-bit-long "storage groups"
- recognize the 17-group preamble to the data on all tracks (TERM, SECOND, 14xSYNC, MARK1)
- do the 5-to-4 conversion on each track from "storage group" to "data group" codes
  for the user data, residual, and CRC fields per Table 2 in the standard
- verify that all those 5-bit codes are valid for data (only 16 of 32 are) on all tracks 
- verify that all the 9-bit converted data bytes have odd parity
- treat each 7 consecutive bytes as user data, and the 8th as the ECC
- verify each ECC (and eventually, use it for error correction)
- extract the residual (length mod 7) data bytes from the ending "residual" group
- verify the "auxiliary" CRC byte
- verify the check bytes in the CRC group

Whirlwind I Decoding Techniques

Whirlwind tracks use a complete flux transitions (low-high, or high-low) for a 1-bit,
and no transitions for a 0-bit. You can specify the polarity with -fluxdir, or let
the program auto-detect the polarity for each block by specifying -fluxdir=AUTO. 

We do peak detection (not zero-crossing detection), and map the top and bottom peaks
to the start or end of a pulse depending on the current polarity.

We treat a transition on either of the replicated tracks as indicating a 1-bit, and
warn about a missing transition if it doesn't also occur in the other track.

At the end pulse of the clock flux transition we check if either or both of the data
tracks had a start pulse flux transition since the last clock end pulse. If so, we
record a data 1-bit. 

Like NRZI, we adjust global bit timing by tracking the transitions on the clock track.

Block marks are pulses on the LSB data line without a clock, but they can happen at
the normal bit spacing before or after blocks. So we have to take special pains to 
not reset the peak-following and skew-delay state in between file marks and blocks.
That makes very difficult the retry mechanism to decode with alternative parameter
sets, which must go back in time to a previous point in the data stream. So it isn't 
implemented yet. See the notes in the code for how we might do it, but at the moment
it isn't needed.


Automatic density detection

The recorded density of a tape is not always known. If the density is 
not specified by the -bpi option, the program will try to determine it 
by calculating the average minimum time between the first several thousand 
flux transitions. If it corresponds to one of the standard densities 
(200, 556, 800, 1600, or 6250), it will choose that for the decoding. 

Track skew compensation

If the head isn't perfectly vertical during either writing or reading, 
there will be consistent timing differences between data from the 
different tracks. If they are too big, it can cause errors in the 
decoding, especially for NRZI.

If we need to insert track de-skewing data delays, they could be 
set by first reading a "master skew tape", if one is available. 
What we do instead is a statistical analysis of some of the 
transitions before trying to decode. See 
https://github.com/LenShustek/readtape/blob/master/flux_transition_dispersion.JPG
for an illustrative graph of data that shows track skew.

If the -deskew parameter is given, the program will attempt to calibrate 
the track skew by looking at the deviation between the actual times of 
the first several thousand flux transitions and the expected times. It 
then uses that to set up delays for the data from the heads whose 
transitions come early. 

Some aspects of head alignment can't be fixed in software and are critical: 
we need a high enough signal-to-noise ratio so that the AGC algorithm 
can see the transitions, and minimal leakage between adjacent tracks. 

ALGORITHM DEBUGGING TOOLS

There is a fair amount of debugging that can be turned on, which 
helps with tuning the algorithms. 

1. Making DEBUG true in decoder.h produces all sorts of diagnostic 
information in the log file. Some of it comes and goes depending on 
whether the various dlog(...) lines in the code are uncommented. Some 
output depends on whether the trace file (see next) is currently being 
generated. The maximum number of lines of debugging output is set by 
DLOG_LINE_LIMIT in decoder.h. 

2. Making TRACEFILE true in decoder.h causes a trace.csv file to be 
produced that can be plotted in Excel to produce a graphical timeline of 
events. Load the file, select columns from C to before the next blank 
column, then "Insert" "2D line chart". 

The start and end of the graph is controlled by code at the bottom on 
decoder.c. 

TRACETRK in decoder.h specifies a particular track to pay attention to. 
TRACEALL says whether to nonetheless plot the analog values (and 
detected peaks, etc.) for all tracks. 

The trace data is buffered before being written to the file, so that we 
can "rewrite history" for events that are discovered late. That happens, 
for example, because the new moving-window algorithm for peak detection 
finds the peaks several clock ticks after they actually happen. 

3. Making PEAK_STATS true in decoder.h causes a stats.csv file to be 
produced which can be plotted in Excel to view the dispersion of peak 
times. Load the file, select all columns (except the average for NRZI),
then "Insert" "2D line chart".

For NRZI there is only one peak, because with odd parity at least one 
track always has a transition at the bit time and we show the peaks 
relative to that. The dispersion is a result of track skew, and with the 
-deskew parameter we use those statistics to calibrate the skew. 

For PE, there are two peaks, corresponding to a one-bit (1/2 bit time 
interval) or zero-bit (1 bit time interval) 

For GCR, where the tracks are skewed relative to each other and decoded 
independently, each track has three peaks corresponding to an interval 
of 0, 1, or 2 zero bits between flux transitions. Since the tracks are
treated independently, the skew does not shift the data on the graph. 
And the skew for GCR is big, typically several complete bit times.

4. For GCR, there is commented-out code in readtape.c that can do a 
comprehensive search of the parameter space to look for candidate
combinations that work.

AUXILIARY UTILITY PROGRAMS

CSVTBIN: This standalone program converts between CSV format text files 
and TBIN format compressed binary files. 

use: csvtbin <options> <basefilename>
options:
  -ntrks=n      the number of tracks; the default is 9
  -order=       input data order for bits 0..ntrks-2 and P, where 0=MSB
                the default is 01234567P for 9 trks, 012345P for 7 trks
                (for Whirlwind: a combination of C L M c l m and x's)
  -skip=n       skip the first n samples
  -subsample=n  use only every nth data sample
  -invert       invert the data so positive peaks are negative and vice versa
  -scale=n      scale the voltages by n, which can be a fraction
  -maxvolts=x   expect x as the maximum plus or minus signal excursion
  -redo         do it over again if maxvolts wasn't big enough
  -read         read tbin and create csv -- otherwise, the opposite
  -showheader   just show the header info of a .tbin file, and check the data
optional documentation that can be recorded in the TBIN file:
  -descr=txt             a description of what is on the tape
  -pe                    PE encoded
  -nrzi                  NRZI encoded
  -gcr                   GCR ecoded
  -whirlwind             Whirlwind I encoded
  -reverse               the tape might have been read or written backwards; mark it so
  -ips=n                 the speed in inches/sec
  -bpi=n                 the density in bits/inch
  -datewritten=ddmmyyyy  when the tape was originally written
  -dateread=ddmmyyyy     when the tape was read and digitized

Although not required, it is strongly suggested that the track order
be specified if it is not the standard MSB...LSB, PARITY.
By doing so the .tbin files will be in the canonical order, and
the readtape program won't need to be told about a non-standard order.

For Whirlwind, the -order= string is put into the .tbin file for use by
readtape later. 

DUMPTAP: This standalone program displays the content of SIMH .tap 
format files with numbers in hex or octal, and/or characters in ASCII, 
EBCDIC, BCD, or Burroughs BIC code, in the style of an old-fashioned 
memory dump. 

use: dumptap <options> <filename>
  the input file is expected to be a SIMH .tap tape image
  the output is to stdout, but can be piped elsewhere
options:
  -b     show BCD characters
  -e     show EBCDIC characters
  -a     show ASCII characters
  -s     show DEC SixBit characters
  -u     show Burroughs B5500 Internal Code characters
  -o     show octal numeric data
  -h     show hex numeric data
  -lnn   each line displays nn bytes

The default is 80 ASCII characters per line and no numeric data.
If the options are "-o -u -l20", the output looks like this:

  file:102784151.tap
     80: 6043212225436060004364422562606000232162   LABEL  0LUKES  0CAS
         6360606000000106110005010001061100050300  T   0016905101690530
         0000000000000000000000000000000000000000  00000000000000000000
         0000050600000005060000000000000000000000  00560005600000000000
  .tap tape mark
  .tap end of medium

We have now incorporated similar but expanded functionality into the 
readtape program with the -textfile option, so the dumptap program is 
not really needed anymore, and is not being kept current. 


....more to come, maybe?....

L. Shustek, 10 April 2018
L. Shustek, 17 May 2018, 8 October 2018, 22 October 2018, 4 August 2019
             Dec 2019, Feb 2022

